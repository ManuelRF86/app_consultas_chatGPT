{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](img/dark_library.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **App de consulta de documentos mediante GPT en AWS**\n",
    "\n",
    "Steven Noboa, María Neches, Manuel Reina Águeda González\n",
    "\n",
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Elaboración de un primer borrador del script y conexión a Langchain\n",
    "+ Primera template html\n",
    "+ Desarrollo del script con una primera base de datos local de prueba\n",
    "+ Conexión a Langchain\n",
    "\n",
    "```python\n",
    "\n",
    " fragment_size = 4096\n",
    "        while True:\n",
    "            parte = archivo.read(fragment_size)\n",
    "            if not parte:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                response = qa_document_chain.run(\n",
    "                    input_document=parte.decode('latin-1'),\n",
    "                    question=pregunta\n",
    "                    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creación de la instancia en AWS - RDS y de la base de datos MySQL\n",
    "+ Creamos una instancia de la base de datos en la plataforma de AWS y nos conectamos a ella (puerto 3306).\n",
    "+ Una vez conectados, creamos también la base de datos definitiva (gpt_database) y la tabla correspondiente (gpt_table), que consta de las siguientes columnas:\n",
    "```python\n",
    "gpt_table (\n",
    "Registro DATETIME,\n",
    "Nombre TEXT,\n",
    "Archivo TEXT,\n",
    "Consulta TEXT,\n",
    "Respuesta TEXT)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Registro*: almacena la fecha y hora de la consulta realizada;\n",
    "- *Nombre*: nombre de la persona que realiza la consulta;\n",
    "- *Archivo*: nombre y extensión del archivo subido para la consulta;\n",
    "- *Consulta*: prompt enviado a gpt para la consulta;\n",
    "- *Respuesta*: resultados de la consulta a gpt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Desarrollo de la App\n",
    "### Primer endpoint: \n",
    "+ La app lee archivos con las extensiones ```.py```, ```.ipynb``` y ```.txt```\n",
    "\n",
    "+ Habilitamos dos opciones para la API Key de OpenAI.\n",
    "    + De forma predeterminada, la key es una variable de entorno y no está disponible para el usuario, de forma que cuando este realiza una consulta la key se introduce automáticamente de forma invisible.\n",
    "    \n",
    "    + La otra opción disponible es un campo que el usuario puede completar con su propia API Key para realizar consultas.\n",
    "\n",
    "```python\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/analizar_documento', methods=['POST'])\n",
    "def analizar_documento():\n",
    "    openai_api_key = request.form.get(\"api_key\")\n",
    "\n",
    "    if openai_api_key:\n",
    "        \n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=openai_api_key)\n",
    "        qa_chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "        qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain) \n",
    "    else:\n",
    "        openai_api_key= openai_key_private\n",
    "    \n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=openai_api_key)\n",
    "        qa_chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "        qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)\n",
    "    \n",
    "    if 'archivo' in request.files:\n",
    "        archivo = request.files['archivo']\n",
    "        if not archivo:\n",
    "            return \"Error: Ningún archivo introducido\"\n",
    "                \n",
    "        nombre = request.form.get('nombre')\n",
    "        if not nombre:\n",
    "            return \"Error: Debe introducir su nombre\"\n",
    "        \n",
    "        pregunta = request.form.get('pregunta')\n",
    "        if not pregunta:\n",
    "            return \"Error: La pregunta no se proporcionó\"\n",
    "        \n",
    "        tipos_aceptados = {'.txt', '.py', '.ipynb'}\n",
    "\n",
    "        if archivo.filename and not any(archivo.filename.lower().endswith(ext) for ext in tipos_aceptados):\n",
    "            error_message = \"Error: Tipo de archivo no admitido\"\n",
    "            return render_template('index.html', error_message=error_message)\n",
    "\n",
    "        # leer el archivo en fragmentos de 4KB\n",
    "                fecha_hora_actual = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                insertar_registro(fecha_hora_actual, nombre,archivo.filename, pregunta, str(response))\n",
    "\n",
    "                return render_template('respuestas.html', pregunta=pregunta, respuesta=str(response))\n",
    "            except Exception as e:\n",
    "                return render_template('respuestas.html', pregunta=pregunta, respuesta=str(e))\n",
    "```\n",
    "### Otros endpoints\n",
    "\n",
    "+ Decidimos crear otros dos endpoints (```/consultas``` y ```/realizar_consulta```) que permiten también realizar consultas sobre los registros de la base de datos filtrándolos por nombre del usuario, aunque este se escriba en minúsculas o no esté completo\n",
    "\n",
    "```python\n",
    "@app.route('/consultas')\n",
    "def consultas():\n",
    "    return render_template('consultas.html')\n",
    "\n",
    "@app.route('/realizar_consulta', methods=['GET'])\n",
    "def realizar_consulta():\n",
    "    nombre = request.args.get('nombre')\n",
    "    conn = pymysql.connect(\n",
    "        host=host,\n",
    "        user=username,\n",
    "        port=port,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "    cursor = conn.cursor(pymysql.cursors.DictCursor)\n",
    "    try:\n",
    "        if nombre:\n",
    "            consulta = f\"SELECT * FROM gpt_table WHERE nombre LIKE LOWER('%{nombre}%')\"\n",
    "        else:\n",
    "            consulta = \"SELECT * FROM gpt_table\"\n",
    "\n",
    "        cursor.execute(consulta)\n",
    "        resultados = cursor.fetchall()\n",
    "    except Exception as e:\n",
    "        print(f\"Error al ejecutar la consulta: {str(e)}\")\n",
    "        resultados = []\n",
    "\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    return render_template('results_BBDD.html', resultados=resultados)```\n",
    "\n",
    "+ Para cada uno de estos endpoints, creamos una interfaz en html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test de la App\n",
    "+ Desarrollamos los [test](../test/test.py) para poner la app a prueba y confirmar que nos devolvía código 200 en todos sus endpoints\n",
    "\n",
    "![imagen](img/test_pasados.jpg)\n",
    "\n",
    "+ Los test están diseñados para poder ejecutarlos sobre la imagen dockerizada, aunque no se disponga del archivo local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dockerización y despliegue de la App\n",
    "+ Creamos los archivos de [Dockerfile](../app/dockerfile) y [requirements](../app/requirements.txt) para dockerizar la app\n",
    "+ Creamos la imagen final en docker (manuelreina/app_gpt:v1) e hicimos un push para subirla a Docker Hub\n",
    "\n",
    "Para ejecutarla, se deberá ejecutar el siguiente comando:\n",
    "\n",
    "```docker run -p 5000:5000 manuelreina/app_gpt:v1```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
